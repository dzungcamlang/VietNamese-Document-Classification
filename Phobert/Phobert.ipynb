{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Project2_Phobert.ipynb",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "VyticpqNftwL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiwJT7tyvgQh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VLFVONgrAuji",
        "colab_type": "text"
      },
      "source": [
        "## Enviroment"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pX_QI3awxT9e",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip3 install transformers\n",
        "!pip3 install vncorenlp\n",
        "!pip3 install fairseq\n",
        "!pip install fastBPE\n",
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V_YiKPpsxrfC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!wget https://public.vinai.io/PhoBERT_base_transformers.tar.gz\n",
        "!tar -xzvf PhoBERT_base_transformers.tar.gz\n",
        "!mkdir -p vncorenlp/models/wordsegmenter\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/VnCoreNLP-1.1.1.jar\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/vi-vocab\n",
        "!wget https://raw.githubusercontent.com/vncorenlp/VnCoreNLP/master/models/wordsegmenter/wordsegmenter.rdr\n",
        "!mv VnCoreNLP-1.1.1.jar vncorenlp/ \n",
        "!mv vi-vocab vncorenlp/models/wordsegmenter/\n",
        "!mv wordsegmenter.rdr vncorenlp/models/wordsegmenter/"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "493fV5knBKC_",
        "colab_type": "text"
      },
      "source": [
        "## Config"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7DxmrK62pnPU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "tqdm.pandas()\n",
        "from torch import nn\n",
        "import json\n",
        "import numpy as np\n",
        "import pickle\n",
        "import os\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, roc_auc_score\n",
        "from transformers import *\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.utils.data\n",
        "import torch.nn.functional as F\n",
        "import argparse\n",
        "from transformers.modeling_utils import *\n",
        "from fairseq.data.encoders.fastbpe import fastBPE\n",
        "from fairseq.data import Dictionary\n",
        "from vncorenlp import VnCoreNLP\n",
        "from scipy.special import softmax\n",
        "import time\n",
        "from torch.utils.data import Dataset"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kkEDS9SXvPnv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args = argparse.Namespace(\n",
        "    train_path='/content/drive/My Drive/Project2/data/preprocessing/train.csv',\n",
        "    test_path='/content/drive/My Drive/Project2/data/preprocessing/test.csv',\n",
        "    dict_path='/content/PhoBERT_base_transformers/dict.txt',\n",
        "    config_path='/content/PhoBERT_base_transformers/config.json',\n",
        "    rdrsegmenter_path='/content/vncorenlp/VnCoreNLP-1.1.1.jar',\n",
        "    pretrained_path='/content/PhoBERT_base_transformers/model.bin',\n",
        "    max_sequence_length=350,\n",
        "    batch_size=16,\n",
        "    accumulation_steps=5,\n",
        "    epochs=5,\n",
        "    fold=5,\n",
        "    seed=69,\n",
        "    lr=3e-5,\n",
        "    early_stop_max_epochs=3,\n",
        "    ckpt_path='/content/drive/My Drive/Project2/models',\n",
        "    bpe_codes='/content/PhoBERT_base_transformers/bpe.codes',\n",
        "    version=3.2\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bh9T_8uvBOU-",
        "colab_type": "text"
      },
      "source": [
        "## Extrac feature"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vv9u389pwj62",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def max_sequence(data_df):\n",
        "    max_seq = 0\n",
        "    for text in data_df.text.values:\n",
        "        max_seq = max(max_seq, len(text.split(' ')))\n",
        "    return max_seq"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7b_8DQec9A0n",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import defaultdict\n",
        "def split_by_label(data_df, train_split=0.8):\n",
        "    by_label = defaultdict(list)\n",
        "    for _, row in data_df.iterrows():\n",
        "        by_label[row.label].append(row.to_dict())\n",
        "    train_list = []\n",
        "    val_list = []\n",
        "    for _, item_list in sorted(by_label.items()):\n",
        "        np.random.shuffle(item_list)\n",
        "        n_total = len(item_list)\n",
        "        n_train = int(train_split*n_total)\n",
        "        train_list.extend(item_list[: n_train])\n",
        "        val_list.extend(item_list[n_train:])\n",
        "    train_df = pd.DataFrame(train_list)\n",
        "    val_df = pd.DataFrame(val_list)\n",
        "    return train_df, val_df\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9GytwU6evaKa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# args = parser.parse_args()\n",
        "\n",
        "\n",
        "np.random.seed(1337)\n",
        "torch.manual_seed(1337)\n",
        "torch.cuda.manual_seed(1337)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "\n",
        "# Load the dictionary\n",
        "\n",
        "\n",
        "# Load training data\n",
        "data_df = pd.read_csv(args.train_path)\n",
        "train_df = data_df[data_df.split == 'train']\n",
        "val_df = data_df[data_df.split == 'val']\n",
        "num_labels = len(set(train_df.label.values))\n",
        "# args.max_sequence_length = max_sequence(train_df)\n",
        "print(args.max_sequence_length)\n",
        "test_df = pd.read_csv(args.test_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvKNqjGsv43z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class LabelEncode(object):\n",
        "    def __init__(self, label=None):\n",
        "        label = set(label);\n",
        "        if len(label) == 0:\n",
        "            token_to_idx = {}\n",
        "        else:\n",
        "          token_to_idx = {y:i for i, y in enumerate(sorted(label))}\n",
        "        self.token_to_idx = token_to_idx\n",
        "        self.idx_to_token = {i: w for w, i in token_to_idx.items()}\n",
        "\n",
        "    def lookup_token(self, token):\n",
        "        return self.token_to_idx[token]\n",
        "\n",
        "    def lookup_index(self, index):\n",
        "        if index not in self.idx_to_token:\n",
        "            raise KeyError(\"the index (%d) is not in the Vocabulary\" % index)\n",
        "        return self.idx_to_token[index]\n",
        "    \n",
        "    def transform(y_pred):\n",
        "        return [self.lookup_index[y] for y in y_pred]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.token_to_idx)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NA9mlmhzr_OM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class TextDataset(Dataset):\n",
        "    def __init__(self, data_df, args, labelencode):\n",
        "        \n",
        "        self.bpe = fastBPE(args=args)\n",
        "        self.data_df = data_df\n",
        "        self.vocab = Dictionary()\n",
        "        self.vocab.add_from_file(args.dict_path)\n",
        "        self.labelencode = labelencode\n",
        "        self.max_len = args.max_sequence_length\n",
        "    def vectorize(self, text):\n",
        "        max_sequence_length = self.max_len\n",
        "        cls_id = 0\n",
        "        eos_id = 2\n",
        "        pad_id = 1\n",
        "        subwords = self.bpe.encode('<s> ' + text + ' </s>')\n",
        "        input_ids = self.vocab.encode_line(subwords, append_eos=False, add_if_not_exist=False).long().tolist()\n",
        "        if len(input_ids) > max_sequence_length:\n",
        "            input_ids = input_ids[:max_sequence_length]\n",
        "            input_ids[-1] = eos_id\n",
        "        else:\n",
        "            input_ids = input_ids + [pad_id, ] * (max_sequence_length - len(input_ids))\n",
        "        output = np.array(input_ids)\n",
        "        return output\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.data_df)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        row = self.data_df.iloc[index]\n",
        "        text = row.text\n",
        "        x = self.vectorize(text)\n",
        "        y = self.labelencode.lookup_token(row.label)\n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BTTQYxjqmxXQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uwh2UtVQw7rO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "labelencode = LabelEncode(train_df.label.tolist())\n",
        "train_dataset = TextDataset(train_df, args, labelencode)\n",
        "valid_dataset = TextDataset(val_df, args, labelencode)\n",
        "test_dataset = TextDataset(test_df, args, labelencode)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7CRi5MA-Aixz",
        "colab_type": "text"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cvadzDq8ELY5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import json\n",
        "def make_train_state(args):\n",
        "    return {\n",
        "        'stop_early': False,\n",
        "        'early_stop_num_epoch': 0,\n",
        "        'early_stop_max_epochs': args.early_stop_max_epochs,\n",
        "        'early_stop_best_val_loss': 1e8,\n",
        "        'epoch_index': 0,\n",
        "        'model_filename': args.ckpt_path + \"/P2_phobert.bin\",\n",
        "        'learning_rate': args.lr,\n",
        "        'train_loss': [],\n",
        "        'val_loss': [],\n",
        "        'test_loss': 0,\n",
        "        'test_acc': 0\n",
        "    }\n",
        "\n",
        "def update_train_state(model, train_state):\n",
        "    if train_state['epoch_index'] == 0:\n",
        "        torch.save(model.state_dict(), train_state['model_filename'])\n",
        "\n",
        "    else:\n",
        "        loss_t = train_state['val_loss'][-1]\n",
        "        if loss_t < train_state['early_stop_best_val_loss']:\n",
        "            torch.save(model.state_dict(), train_state['model_filename'])\n",
        "            train_state['early_stop_num_epoch'] = 0\n",
        "            train_state['early_stop_best_val_loss'] = loss_t\n",
        "        else:\n",
        "            train_state['early_stop_num_epoch'] += 1\n",
        "\n",
        "        if train_state['early_stop_num_epoch'] >= train_state['early_stop_max_epochs']:\n",
        "            train_state['stop_early'] = True\n",
        "\n",
        "    return train_state\n",
        "  \n",
        "def save_train_state(train_state):\n",
        "    with open('train_state_{}.json'.format(args.version), 'w') as fp:\n",
        "        json.dump(train_state, fp)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wxYulYxqFwOu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def score(y_truth, y_preds):\n",
        "    y_preds = softmax(y_preds, axis=1)\n",
        "    y_preds = np.argmax(y_preds, axis=1)\n",
        "    acc = accuracy_score(y_truth, y_preds)\n",
        "    f1 = f1_score(y_truth, y_preds, average='macro')\n",
        "    precision = precision_score(y_truth, y_preds, average='macro')\n",
        "    recall = recall_score(y_truth, y_preds, average='macro')\n",
        "    return acc, f1, precision, recall"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "22qaQ5yrrA0o",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from transformers import *\n",
        "from transformers import RobertaConfig\n",
        "\n",
        "\n",
        "class RobertaForClassification(BertPreTrainedModel):\n",
        "   config_class = RobertaConfig\n",
        "   base_model_prefix = \"roberta\"\n",
        "   def __init__(self, config):\n",
        "       super(RobertaForClassification, self).__init__(config)\n",
        "       self.num_labels = config.num_labels\n",
        "       self.roberta = RobertaModel(config)\n",
        "       self.qa_outputs = nn.Linear(4*config.hidden_size, self.num_labels)\n",
        "\n",
        "       self.init_weights()\n",
        "\n",
        "   def forward(self, input_ids, attention_mask=None, token_type_ids=None, position_ids=None, head_mask=None,\n",
        "                start_positions=None, end_positions=None):\n",
        "\n",
        "       outputs = self.roberta(input_ids,\n",
        "                            attention_mask=attention_mask,\n",
        "#                            token_type_ids=token_type_ids,\n",
        "                            position_ids=position_ids,\n",
        "                            head_mask=head_mask)\n",
        "       cls_output = torch.cat((outputs[2][-1][:,0, ...],outputs[2][-2][:,0, ...], outputs[2][-3][:,0, ...], outputs[2][-4][:,0, ...]),-1)\n",
        "       logits = self.qa_outputs(cls_output)\n",
        "       return logits"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WTgMflyz62jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def compute_accuracy(y_pred, y_target):\n",
        "    y_pred_indices = np.argmax(y_pred, axis=1)\n",
        "    n_correct = np.equal(y_pred_indices, y_target).sum().item()\n",
        "    return n_correct / len(y_pred_indices)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HDnmz9wAIlsp",
        "colab_type": "text"
      },
      "source": [
        "# Train"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hTxoAwGs8yAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Load model\n",
        "config = RobertaConfig.from_pretrained(\n",
        "    args.config_path,\n",
        "    output_hidden_states=True,\n",
        "    num_labels=num_labels\n",
        ")\n",
        "model_bert = RobertaForClassification.from_pretrained(args.pretrained_path, config=config)\n",
        "model_bert.cuda()\n",
        "\n",
        "if torch.cuda.device_count():\n",
        "    print(f\"Training using {torch.cuda.device_count()} gpus\")\n",
        "    model_bert = nn.DataParallel(model_bert)\n",
        "    tsfm = model_bert.module.roberta\n",
        "else:\n",
        "    tsfm = model_bert.roberta"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pztaa4wN8lvp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creating optimizer and lr schedulers\n",
        "param_optimizer = list(model_bert.named_parameters())\n",
        "no_decay = ['bias', 'LayerNorm.bias', 'LayerNorm.weight']\n",
        "optimizer_grouped_parameters = [\n",
        "    {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)], 'weight_decay': 0.01},\n",
        "    {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)], 'weight_decay': 0.0}\n",
        "]\n",
        "num_train_optimization_steps = int(args.epochs*len(train_df)/args.batch_size/args.accumulation_steps)\n",
        "optimizer = AdamW(optimizer_grouped_parameters, lr=args.lr, correct_bias=False)  # To reproduce BertAdam specific behavior set correct_bias=False\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=100, num_training_steps=num_train_optimization_steps)  # PyTorch scheduler\n",
        "scheduler0 = get_constant_schedule(optimizer)  # PyTorch scheduler\n",
        "loss_f = nn.CrossEntropyLoss()\n",
        "\n",
        "if not os.path.exists(args.ckpt_path):\n",
        "    os.mkdir(args.ckpt_path)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ob3Eub9RAiVl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "args.epochs = 6\n",
        "print(args.max_sequence_length)\n",
        "train_state = make_train_state(args)\n",
        "# tq = tqdm(range(args.epochs + 1))\n",
        "for child in tsfm.children():\n",
        "    for param in child.parameters():\n",
        "        if not param.requires_grad:\n",
        "            print(\"whoopsies\")\n",
        "        param.requires_grad = False\n",
        "frozen = True\n",
        "for epoch in range(args.epochs):\n",
        "    start_time = time.time()\n",
        "    if epoch > 0 and frozen:\n",
        "        for child in tsfm.children():\n",
        "            for param in child.parameters():\n",
        "                param.requires_grad = True\n",
        "        frozen = False\n",
        "        del scheduler0\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    \n",
        "    train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=args.batch_size, shuffle=True)\n",
        "    valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    optimizer.zero_grad()\n",
        "    # pbar = tqdm(enumerate(train_loader),total=len(train_loader),leave=False)\n",
        "    for i, (x_batch, y_batch) in enumerate(train_loader):\n",
        "        model_bert.train()\n",
        "        y_pred = model_bert(torch.tensor(x_batch, dtype=torch.long).cuda(), attention_mask=(torch.tensor(x_batch, dtype=torch.long)>0).cuda())\n",
        "        loss =  F.cross_entropy(y_pred.cuda(),torch.tensor(y_batch, dtype=torch.long).cuda())\n",
        "        loss = loss.mean()\n",
        "        loss.backward()\n",
        "        if i % args.accumulation_steps == 0 or i == len(train_loader) - 1:\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "            if not frozen:\n",
        "                scheduler.step()\n",
        "            else:\n",
        "                scheduler0.step()\n",
        "        y_pred = y_pred.squeeze().detach().cpu().numpy()\n",
        "        y_batch = y_batch.detach().cpu().numpy()\n",
        "        acc_t = compute_accuracy(y_pred, y_batch)\n",
        "        running_acc += (acc_t-running_acc)/(i + 1)\n",
        "        if(i % 100 == 0):\n",
        "            print(\"Train: epoch {} step {} - {}\".format(epoch, i, running_acc))\n",
        "        del x_batch, y_batch, y_pred, loss\n",
        "        torch.cuda.empty_cache()\n",
        "    train_state['train_loss'].append(running_acc)\n",
        "    model_bert.eval()\n",
        "    running_loss = 0\n",
        "    running_acc = 0\n",
        "    for i, (x_batch, y_batch) in enumerate(valid_loader):\n",
        "        torch.no_grad\n",
        "        y_pred = model_bert(torch.tensor(x_batch, dtype=torch.long).cuda(), attention_mask=(torch.tensor(x_batch, dtype=torch.long)>0).cuda())\n",
        "        loss =  F.cross_entropy(y_pred.cuda(),torch.tensor(y_batch, dtype=torch.long).cuda())\n",
        "        loss = loss.mean()\n",
        "        loss_t = loss.item()\n",
        "        running_loss += (loss_t-running_loss)/(i + 1)\n",
        "        y_pred = y_pred.squeeze().detach().cpu().numpy()\n",
        "        y_batch = y_batch.numpy()\n",
        "        acc_t = compute_accuracy(y_pred, y_batch)\n",
        "        running_acc += (acc_t-running_acc)/(i + 1)\n",
        "        del x_batch, y_batch, y_pred, loss\n",
        "        torch.cuda.empty_cache()\n",
        "    train_state['val_loss'].append(running_loss)\n",
        "    train_state = update_train_state(model_bert, train_state)\n",
        "    print(\"Val: epoch\", epoch, f\"    loss={running_loss:.4f}\", f\"    acc={running_acc:.4f}\", \"    time({}s)\".format(time.time() - start_time))\n",
        "    torch.cuda.empty_cache()\n",
        "    if train_state['stop_early']:\n",
        "        print(\"Stop early!\")\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wps0fPGDeFMU",
        "colab_type": "text"
      },
      "source": [
        "## Save model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eiBazllreFC5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "torch.save(model_bert, args.ckpt_path + '/P2_phobert.pth')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1f9QJQYRCX_b",
        "colab_type": "text"
      },
      "source": [
        "# Evaluate"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zqTOPAB2Ectk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import numpy as np\n",
        "from sklearn.metrics import confusion_matrix\n",
        "def plot_confusion_matrix(cm,\n",
        "                          target_names,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=None,\n",
        "                          normalize=True,\n",
        "                          results_path='/content/drive/My Drive/Work/IC/results'):\n",
        "\n",
        "    accuracy = np.trace(cm) / float(np.sum(cm))\n",
        "    misclass = 1 - accuracy\n",
        "\n",
        "    if cmap is None:\n",
        "        cmap = plt.get_cmap('Blues')\n",
        "\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "\n",
        "    if target_names is not None:\n",
        "        tick_marks = np.arange(len(target_names))\n",
        "        plt.xticks(tick_marks, target_names, rotation=90)\n",
        "        plt.yticks(tick_marks, target_names)\n",
        "\n",
        "    if normalize:\n",
        "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
        "\n",
        "    thresh = cm.max() / 1.5 if normalize else cm.max() / 2\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        if normalize:\n",
        "            plt.text(j, i, \"{:0.2f}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "        else:\n",
        "            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n",
        "                     horizontalalignment=\"center\",\n",
        "                     color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label\\naccuracy={:0.2f}; misclass={:0.2f}'.format(\n",
        "        accuracy, misclass))\n",
        "#     plt.show()\n",
        "    if not os.path.exists(results_path):\n",
        "        os.mkdir(results_path)\n",
        "    if normalize:\n",
        "        plt.savefig(results_path + '/normalize_confusion_matrix.png')\n",
        "    else:\n",
        "        plt.savefig(results_path+ '/confusion_matrix.png')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZWezNFPYm_YN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "config = RobertaConfig.from_pretrained(\n",
        "    args.config_path,\n",
        "    output_hidden_states=True,\n",
        "    num_labels=num_labels\n",
        ")\n",
        "model_path = '/content/drive/My Drive/Project2/models/P2_phobert.pth'\n",
        "model_state_dict = torch.load(model_path)\n",
        "model_bert = torch.load(model_path)\n",
        "for param in model_bert.parameters():\n",
        "    param.requires_grad = False\n",
        "model_bert.eval()\n",
        "device = torch.device(\"cuda\")\n",
        "model_bert.to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Cj302snBrLX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_bert.eval()\n",
        "running_acc = 0\n",
        "test_preds = []\n",
        "test_truth = []\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=args.batch_size, shuffle=False)\n",
        "for i, (x_batch, y_batch) in enumerate(test_loader):\n",
        "    torch.no_grad\n",
        "    y_pred = model_bert(torch.tensor(x_batch, dtype=torch.long).cuda(), attention_mask=(torch.tensor(x_batch, dtype=torch.long)>0).cuda())\n",
        "    y_pred = y_pred.squeeze().detach().cpu().numpy()\n",
        "    y_pred = softmax(y_pred, axis=1)\n",
        "    y_pred1 = np.argmax(y_pred, axis=1)\n",
        "    y_batch = y_batch.numpy()\n",
        "    if len(test_preds) == 0:\n",
        "        test_preds = y_pred1\n",
        "        test_truth = y_batch\n",
        "    else:\n",
        "        test_preds = np.concatenate([test_preds, y_pred1], axis=0)\n",
        "        test_truth = np.concatenate([test_truth, y_batch], axis=0)\n",
        "acc = accuracy_score(test_preds, test_truth)\n",
        "print(\"acc: \", acc)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G3gZk4E7BgGu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TvCeBJHtBgAB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t57e16HrEMqr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = set(test_df.label.values)\n",
        "y_labels = test_df.label.values\n",
        "test_preds = label(test_preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4AA5kroM7AZS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "classes = list(sorted(classes))\n",
        "print(test_preds)\n",
        "print(y_labels)\n",
        "print(classes)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ncOawoUVEpw8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(y_true=y_labels, y_pred=test_preds, labels=classes)\n",
        "plot_confusion_matrix(cm, normalize=True, target_names=classes,\n",
        "                      title=\"Confusion Matrix IC(normalize)\")\n",
        "plot_confusion_matrix(cm, normalize=False, target_names=classes,\n",
        "                      title=\"Confusion Matrix IC\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeYBcpS3GFO9",
        "colab_type": "text"
      },
      "source": [
        "# Inference"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JnhrHfEdigqI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_text(text, vocab, bpe, max_sequence_length):\n",
        "    output = np.zeros(max_sequence_length)\n",
        "    cls_id = 0\n",
        "    eos_id = 2\n",
        "    pad_id = 1\n",
        "    subwords = bpe.encode('<s> ' + text + ' </s>')\n",
        "    input_ids = vocab.encode_line(subwords, append_eos=False, add_if_not_exist=False).long().tolist()\n",
        "    if len(input_ids) > max_sequence_length:\n",
        "        input_ids = input_ids[:max_sequence_length]\n",
        "        input_ids[-1] = eos_id\n",
        "    else:\n",
        "        input_ids = input_ids + [pad_id, ] * (max_sequence_length - len(input_ids))\n",
        "    output = np.array([input_ids])\n",
        "    return output\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ctS0RfceEDJp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"Cho mình xem xe ăn dăm với!\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oz5JxInvD-Uy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# x = convert_text(text, vocab, bpe,args.max_sequence_length)\n",
        "# print(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cQlRvuuX9lNu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def predict(text):\n",
        "    x = convert_text(text, vocab, bpe,args.max_sequence_length)\n",
        "    x = torch.tensor(x, dtype=torch.long)\n",
        "    model_bert.eval()\n",
        "    torch.no_grad\n",
        "    y_pred = model_bert(x.cuda(), attention_mask=(x>0).cuda())\n",
        "    y_pred = y_pred.squeeze().detach().cpu().numpy()\n",
        "    y_pred = np.exp(y_pred)/sum(np.exp(y_pred))\n",
        "    y_pred = np.argmax(y_pred)\n",
        "    return encoder.inverse_transform([y_pred])[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "448aQNocMRg2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xZt1WR0M13vy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "text = \"inbox cho minh\"\n",
        "print(text, \"-->\", predict(text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fVrFWQf5W5Vc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = "
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}